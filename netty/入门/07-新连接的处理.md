### 常见问题

netty 是哪里检查有新连接的接入的？

boos线程轮换出accept事件，然后通过jdk底层创建这条连接

新连接是怎样注册到NioEventLoop线程的？

boos线程通过next方法，调用线程chooser来注册NioEventLoop线程的



### netty 新连接的接入的处理逻辑

1. 检查新连接
2. 创建NioSocketChannel
3. 分配线程及注册selector	
4. 向selector注册读事件



#### 检查新连接

检查新连接入口：

NioEventLoop.processSelectedKeys();

​		NioServerSocketChannel.AbstractNioMessageChannel.NioMessageUnsafe.read(); // NioServerSocketChannel处理就绪操作

​			doReadMessages(readBuf); 	while循环

​					SocketUtils.accept(javaChannel()); java 原生accept

​					buf.add(new NioSocketChannel(this, ch));  创建NioSocketChannel

​					

​					pipeline.fireChannelRead(readBuf.get(i)); 到ServerBootstrapAcceptor里处理分配线程及注册selector	

检查新连接之后会在服务端首次启动时对NioServerSocketChannel添加的pipeline组件ServerBootstrapAcceptor里处理分配线程及注册selector	





```java
 private void processSelectedKeys() {
     if (selectedKeys != null) {
         // selectedKeys是优化后的一定有值，这里最终会调用到这个方法里面。
         processSelectedKeysOptimized();
     } else {
         processSelectedKeysPlain(selector.selectedKeys());
     }
}
// 最终会调用到这个方法里面。
private void processSelectedKeysOptimized() {
    // 遍历selectedKeys: publicSelectedKeys
    for (int i = 0; i < selectedKeys.size; ++i) {
        final SelectionKey k = selectedKeys.keys[i];
        // null out entry in the array to allow to have it GC'ed once the Channel close
        // See https://github.com/netty/netty/issues/2363
        selectedKeys.keys[i] = null;
        //在我们之前注册的时候，将NioServerSocketChannel 当作一个attachment，绑定到了这个Jdk Channel 中，这里可以通过SelectionKey实例拿到
        final Object a = k.attachment();
		//netty封装的将NioServerSocketChannel
        if (a instanceof AbstractNioChannel) {
            // netty对封装的Channel具体实现。
            processSelectedKey(k, (AbstractNioChannel) a);
        } else {
            @SuppressWarnings("unchecked")
            NioTask<SelectableChannel> task = (NioTask<SelectableChannel>) a;
            processSelectedKey(k, task);
        }

        if (needsToSelectAgain) {
            // null out entries in the array to allow to have it GC'ed once the Channel close
            // See https://github.com/netty/netty/issues/2363
            selectedKeys.reset(i + 1);

            selectAgain();
            i = -1;
        }
    }
}

// 最终会调用到这个方法里面
private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) {
    // 拿到这个channel的unsafe。
    final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe();
    // 判断这个SelectionKey是否合法，因为这个连接可能有点问题
    if (!k.isValid()) {
        final EventLoop eventLoop;
        try {
            eventLoop = ch.eventLoop();
        } catch (Throwable ignored) {
            // If the channel implementation throws an exception because there is no event loop, we ignore this
            // because we are only trying to determine if ch is registered to this event loop and thus has authority
            // to close ch.
            return;
        }
        // Only close ch if ch is still registered to this EventLoop. ch could have deregistered from the event loop
        // and thus the SelectionKey could be cancelled as part of the deregistration process, but the channel is
        // still healthy and should not be closed.
        // See https://github.com/netty/netty/issues/5125
        if (eventLoop == this) {
            // close the channel if the key is not valid anymore
            unsafe.close(unsafe.voidPromise());
        }
        return;
    }

    try {
        // 如果是合法的，就拿到这个SelectionKey上的IO事件。
        // readyOps用于判断这个事件的具体是哪个。
        // 判断是否是OP_CONNECT事件。
        int readyOps = k.readyOps();
        // We first need to call finishConnect() before try to trigger a read(...) or write(...) as otherwise
        // the NIO JDK channel implementation may throw a NotYetConnectedException.
        // 判断是否是OP_CONNECT事件。这个事件一般是客户端用的，客户端连接服务端时用到
        if ((readyOps & SelectionKey.OP_CONNECT) != 0) {
            // remove OP_CONNECT as otherwise Selector.select(..) will always return without blocking
            // See https://github.com/netty/netty/issues/924
            int ops = k.interestOps();
            ops &= ~SelectionKey.OP_CONNECT;
            k.interestOps(ops);

            unsafe.finishConnect();
        }

        // Process OP_WRITE first as we may be able to write some queued buffers and so free memory.
        // 判断是否是OP_WRITE事件。
        if ((readyOps & SelectionKey.OP_WRITE) != 0) {
            // Call forceFlush which will also take care of clear the OP_WRITE once there is nothing left to write
            ch.unsafe().forceFlush();
        }

        // Also check for readOps of 0 to workaround possible JDK bug which may otherwise lead
        // to a spin loop
        // 判断是否是OP_READ或者OP_ACCEPT事件
        if ((readyOps & (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) {
            // 重点关注：NioServerSocketChannel是OP_ACCEPT事件，NioSocketChannel是OP_READ事件
            unsafe.read();
        }
    } catch (CancelledKeyException ignored) {
        unsafe.close(unsafe.voidPromise());
    }
}




```



**NioServerSocketChannel.AbstractNioMessageChannel.NioMessageUnsafe.read();**

```java
private final class NioMessageUnsafe extends AbstractNioUnsafe {

    private final List<Object> readBuf = new ArrayList<Object>();

    @Override
    public void read() {
        // 必须是当前线程才能操作
        assert eventLoop().inEventLoop();
        // 服务端的config--NioMessageUnsafe就是处理NioServerSocketChannel的
        final ChannelConfig config = config();
        // 服务端的pipeline
        final ChannelPipeline pipeline = pipeline();
        // 缓冲区大小，速度（默认一次最大读取16个）分配器
        final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle();
        allocHandle.reset(config);

        boolean closed = false;
        Throwable exception = null;
        try {
            try {
                do {
                    int localRead = doReadMessages(readBuf);
                    if (localRead == 0) {
                        break;
                    }
                    if (localRead < 0) {
                        //没有新连接接入了-accept没有了
                        closed = true;
                        break;
                    }
                    // 每accept一次添加一个数
                    allocHandle.incMessagesRead(localRead);
                    // 判断是否超过每次最大个数
                    // 没超过就继续accept新连接
                } while (continueReading(allocHandle));
            } catch (Throwable t) {
                exception = t;
            }

            int size = readBuf.size();
            for (int i = 0; i < size; i ++) {
                readPending = false;
                // 分配线程及注册selector
                // 调用ServerBootstrapAcceptor 的fireChannelRead 分配线程及注册selector
                pipeline.fireChannelRead(readBuf.get(i));
            }
            readBuf.clear();
            allocHandle.readComplete();
            pipeline.fireChannelReadComplete();

            if (exception != null) {
                closed = closeOnReadError(exception);

                pipeline.fireExceptionCaught(exception);
            }

            if (closed) {
                inputShutdown = true;
                if (isOpen()) {
                    close(voidPromise());
                }
            }
        } finally {
            // Check if there is a readPending which was not processed yet.
            // This could be for two reasons:
            // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method
            // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method
            //
            // See https://github.com/netty/netty/issues/2254
            if (!readPending && !config.isAutoRead()) {
                removeReadOp();
            }
        }
    }
}



@Override
protected int doReadMessages(List<Object> buf) throws Exception {
    // 拿到jdk底层的channel
    SocketChannel ch = SocketUtils.accept(javaChannel());

    try {
        if (ch != null) {
            // 将拿到jdk底层的channel封装成netty的NioSocketChannel
            // 放到一个临时List集合中--处理完连接就会清空readBuf.clear();
            buf.add(new NioSocketChannel(this, ch));
            return 1;
        }
    } catch (Throwable t) {
        logger.warn("Failed to create a new channel from an accepted socket.", t);

        try {
            ch.close();
        } catch (Throwable t2) {
            logger.warn("Failed to close a socket.", t2);
        }
    }

    return 0;
}
```



#### 创建NioSocketChannel

NioSocketChannel 是对java底层channel的封装

在 java底层accept之后：

SocketUtils.accept(javaChannel()) 创建 NioSocketChannel

buf.add(new NioSocketChannel(this, ch));



创建NioSocketChannel入口：

new NioSocketChannel(Channel parent, SocketChannel socket)

​		父类AbstractNioChannel

​				保存读事件readInterestOp=SelectionKey.OP_READ  

​					    等到ServerBootstrapAcceptor.channelRead.register注册完成

​					    调用fireChannelActive.Head.channelActive里面的readIfIsAutoRead，去改变InterestOp

​				ch.configureBlocking(false); 

​				创建 ID,unsafe,pipeline 三大组件

​		new NioSocketChannelConfig(this, socket.socket());

​				默认设置setTcpNoDelay(true); 禁止nagle算法，小的数据包尽量发过去，降低延迟）--非安卓都禁止nagle算法



总结：分两步

第一步调用父类构造方法，设置该channel阻塞为false和保存读事件，接下来创建 ID,unsafe,pipeline 三大组件

第二步创建channel相关的config里面重要的是禁止nagle算法

```java

public NioSocketChannel(Channel parent, SocketChannel socket) {
    // 第一步调用父类构造方法
    super(parent, socket);
    // 第二步创建channel相关的config
    config = new NioSocketChannelConfig(this, socket.socket());
}
// 父类构造方法
protected AbstractNioChannel(Channel parent, SelectableChannel ch, int readInterestOp) {
    // 创建 ID,unsafe,pipeline 三大组件
    super(parent);
    this.ch = ch;
    // 保存读事件
    this.readInterestOp = readInterestOp;
    try {
        // 设置该channel阻塞为false
        ch.configureBlocking(false);
    } catch (IOException e) {
        try {
            ch.close();
        } catch (IOException e2) {
            logger.warn(
                "Failed to close a partially initialized socket.", e2);
        }

        throw new ChannelException("Failed to enter non-blocking mode.", e);
    }
}
// 创建 ID,unsafe,pipeline 三大组件
protected AbstractChannel(Channel parent) {
    this.parent = parent;
    id = newId();
    unsafe = newUnsafe();
    pipeline = newChannelPipeline();
}

 // 第二步创建channel相关的config
private NioSocketChannelConfig(NioSocketChannel channel, Socket javaSocket) {
    super(channel, javaSocket);
    //写人buff的最大maxBytesPerGatheringWrite值是操作系统给的SO_SNDBUF值的2倍，防止操作系统写入速度比我们还快
    //SO_SNDBUF
    //Socket参数，TCP数据发送缓冲区大小。该缓冲区即TCP发送滑动窗口，linux操作系统可使用命令：cat /proc/sys/net/ipv4/tcp_smem查询其大小。
    calculateMaxBytesPerGatheringWrite();
    //SO_RCVBUF
    //Socket参数，TCP数据接收缓冲区大小。该缓冲区即TCP接收滑动窗口，linux操作系统可使用命令：cat /proc/sys/net/ipv4/tcp_rmem查询其大小。
    //一般情况下，该值可由用户在任意时刻设置，但当设置值超过64KB时，需要在连接到远端之前设置。
}
//创建channel相关的config
public DefaultSocketChannelConfig(SocketChannel channel, Socket javaSocket) {
    super(channel);
    this.javaSocket = ObjectUtil.checkNotNull(javaSocket, "javaSocket");

    // Enable TCP_NODELAY by default if possible.
    // private static final boolean CAN_ENABLE_TCP_NODELAY_BY_DEFAULT = !isAndroid();
	// 如果不是Android都设置禁止nagle算法	
    if (PlatformDependent.canEnableTcpNoDelayByDefault()) {
        try {
            setTcpNoDelay(true);
        } catch (Exception e) {
            // Ignore.
        }
    }
}

//两个主要的byteBuff分配器
public class DefaultChannelConfig implements ChannelConfig {
    //默认的内存分配器 small--256
    private volatile ByteBufAllocator allocator = ByteBufAllocator.DEFAULT;
    //接收数据内存分配器--默认接收2048长度的byteBuff
    //（一次请求可能多次接收数据）然后，旧的和新的累计，当做新的长度byteBuff
    //static final int DEFAULT_MINIMUM = 64; 64B
    // Use an initial value that is bigger than the common MTU of 1500
    //static final int DEFAULT_INITIAL = 2048; 2K
   // static final int DEFAULT_MAXIMUM = 65536; 64K
    private volatile RecvByteBufAllocator rcvBufAllocator;
    private volatile MessageSizeEstimator msgSizeEstimator = DEFAULT_MSG_SIZE_ESTIMATOR;

    private volatile int connectTimeoutMillis = DEFAULT_CONNECT_TIMEOUT;
    private volatile int writeSpinCount = 16;
}



```





#### 分配线程及注册selector

在服务端首次启动的时候 添加的服务端特有的pipeline组件ServerBootstrapAcceptor 

```java
//服务端首次启动的时候，调用
private final class NioMessageUnsafe extends AbstractNioUnsafe {

    private final List<Object> readBuf = new ArrayList<Object>();

    @Override
    public void read() {
        // 必须是当前线程才能操作
        assert eventLoop().inEventLoop();
        // 服务端的config--NioMessageUnsafe就是处理NioServerSocketChannel的
        final ChannelConfig config = config();
        // 服务端的pipeline
        final ChannelPipeline pipeline = pipeline();
        // 缓冲区大小，速度（默认一次最大读取16个）分配器
        final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle();
        allocHandle.reset(config);

        boolean closed = false;
        Throwable exception = null;
        try {
            try {
                do {
                    int localRead = doReadMessages(readBuf);
                    if (localRead == 0) {
                        break;
                    }
                    if (localRead < 0) {
                        //没有新连接接入了-accept没有了
                        closed = true;
                        break;
                    }
                    // 每accept一次添加一个数
                    allocHandle.incMessagesRead(localRead);
                    // 判断是否超过每次最大个数
                    // 没超过就继续accept新连接
                } while (continueReading(allocHandle));
            } catch (Throwable t) {
                exception = t;
            }

            int size = readBuf.size();
            // 这里对accept的NioSocketChannel进行fireChannelRead事件传播
            // 服务端首次启动时对NioServerSocketChannel添加的pipeline组件ServerBootstrapAcceptor
            // 在ServerBootstrapAcceptor里面的channelRead 分配线程及注册selector
            for (int i = 0; i < size; i ++) {
                readPending = false;
                // 分配线程及注册selector
                pipeline.fireChannelRead(readBuf.get(i));
            }
            readBuf.clear();
            allocHandle.readComplete();
            pipeline.fireChannelReadComplete();

            if (exception != null) {
                closed = closeOnReadError(exception);

                pipeline.fireExceptionCaught(exception);
            }

            if (closed) {
                inputShutdown = true;
                if (isOpen()) {
                    close(voidPromise());
                }
            }
        } finally {
            // Check if there is a readPending which was not processed yet.
            // This could be for two reasons:
            // * The user called Channel.read() or ChannelHandlerContext.read() in channelRead(...) method
            // * The user called Channel.read() or ChannelHandlerContext.read() in channelReadComplete(...) method
            //
            // See https://github.com/netty/netty/issues/2254
            if (!readPending && !config.isAutoRead()) {
                removeReadOp();
            }
        }
    }
}
```





#### ServerBootstrapAcceptor 

回顾：服务端NioServerSocketChannel 的 pipeline 构成

ServerBootstrapAcceptor 是服务端特有的

Head   --> ServerBootstrapAcceptor  --> Tail



![](img\2022-09-02 131203.png)



ServerBootstrapAcceptor的channelRead主要三件事

1. 添加用户自定义的childHandler
2. 设置option和attr
3. 用workGroup--选择NioEventLoop注册selector
4. 用workGroup--向selector注册读事件



```java
//ServerBootstrapAcceptor.channelRead
public void channelRead(ChannelHandlerContext ctx, Object msg) {
    final Channel child = (Channel) msg;
	// NioSocketChannel添加用户自定义的childHandler
    child.pipeline().addLast(childHandler);
	// NioSocketChannel设置TCP的option：TCP -- KEEPALIVE=true
    setChannelOptions(child, childOptions, logger);
    // NioSocketChannel设置自定义的attr：密钥
    setAttributes(child, childAttrs);

    try {
        //workGroup.注册
        //里面会去执行 eventLoop.execute()
        //eventLoop.execute启用线程去执行
        childGroup.register(child).addListener(new ChannelFutureListener() {
            @Override
            public void operationComplete(ChannelFuture future) throws Exception {
                if (!future.isSuccess()) {
                    forceClose(child, future.cause());
                }
            }
        });
    } catch (Throwable t) {
        forceClose(child, t);
    }
}


//设置TCP的option，就是将option放到config()中操作，因为需要校验参数是否是TCP支持的
private static void setChannelOption(
    Channel channel, ChannelOption<?> option, Object value, InternalLogger logger) {
    try {
        if (!channel.config().setOption((ChannelOption<Object>) option, value)) {
            logger.warn("Unknown channel option '{}' for channel '{}'", option, channel);
        }
    } catch (Throwable t) {
        logger.warn(
            "Failed to set channel option '{}' with value '{}' for channel '{}'", option, value, channel, t);
    }
}
//设置定义的attr：不像ption需要校验，直接设置
static void setAttributes(Channel channel, Map.Entry<AttributeKey<?>, Object>[] attrs) {
    for (Map.Entry<AttributeKey<?>, Object> e: attrs) {
        @SuppressWarnings("unchecked")
        AttributeKey<Object> key = (AttributeKey<Object>) e.getKey();
        channel.attr(key).set(e.getValue());
    }
}

//workGroup.MultithreadEventLoopGroup
public ChannelFuture register(Channel channel) {
    return next().register(channel);
}

//MultithreadEventLoopGroup
public EventExecutor next() {
    return chooser.next();
}
// chooser 则是在创建NioEventLoopGroup的时候赋值的线程选择器

//chooser = chooserFactory.newChooser(children);
public EventExecutorChooser newChooser(EventExecutor[] executors) {
    //NioEventLoopGroup的NioEventLoop是数组
    //idx = new AtomicInteger()每次加一
    //如果是2的指数幂：idx&（length-1)
    //不是则idx%length
    if (isPowerOfTwo(executors.length)) {
        return new PowerOfTwoEventExecutorChooser(executors);
    } else {
        return new GenericEventExecutorChooser(executors);
    }
}

// next()得到NioEventLoop 调用SingleThreadEventLoop.register
public ChannelFuture register(Channel channel) {
    return register(new DefaultChannelPromise(channel, this));
}

public ChannelFuture register(final ChannelPromise promise) {
    ObjectUtil.checkNotNull(promise, "promise");
    //promise.channel()就是传过来的NioSocketChannel
    //NioSocketChannel的unsafe()得到NioByteUnsafe
    //调用NioByteUnsafe.register
    promise.channel().unsafe().register(this, promise);
    return promise;
}


//NioByteUnsafe.AbstractNioUnsafe.AbstractUnsafe.register
public final void register(EventLoop eventLoop, final ChannelPromise promise) {
    ....
    AbstractChannel.this.eventLoop = eventLoop;
	// 是否是本NioEventLoop调用
    // 由于是NioServerSocketChannel给NioSocketChannel分配线程及注册的
    // 所以这里不是本线程
    if (eventLoop.inEventLoop()) {
        register0(promise);
    } else {
        try {
            // 让NioSocketChannel的eventLoop去调用
            eventLoop.execute(new Runnable() {
                @Override
                public void run() {
                    // 调用注册
                    register0(promise);
                }
            });
        } catch (Throwable t) {
            logger.warn(
                "Force-closing a channel whose registration task was not accepted by an event loop: {}",
                AbstractChannel.this, t);
            closeForcibly();
            closeFuture.setClosed();
            safeSetFailure(promise, t);
        }
    }
}

private void register0(ChannelPromise promise) {
    try {
        // check if the channel is still open as it could be closed in the mean time when the register
        // call was outside of the eventLoop
        if (!promise.setUncancellable() || !ensureOpen(promise)) {
            return;
        }
        boolean firstRegistration = neverRegistered;
        // 实际注册--调用java底层去注册
        doRegister();
        neverRegistered = false;
        registered = true;

        // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the
        // user may already fire events through the pipeline in the ChannelFutureListener.
        pipeline.invokeHandlerAddedIfNeeded();

        safeSetSuccess(promise);
        pipeline.fireChannelRegistered();
        // Only fire a channelActive if the channel has never been registered. This prevents firing
        // multiple channel actives if the channel is deregistered and re-registered.
        // 注册完成
        if (isActive()) {
            //首次注册需要传播channelActive事件
            if (firstRegistration) {
                // 首次注册完成-传播channelActive事件
                // fireChannelActive默认从HeadContext的channelActive 开始
                pipeline.fireChannelActive();
            } else if (config().isAutoRead()) {
                // This channel was registered before and autoRead() is set. This means we need to begin read
                // again so that we process inbound data.
                //
                // See https://github.com/netty/netty/issues/4805
                // 
                beginRead();
            }
        }
    } catch (Throwable t) {
        // Close the channel directly to avoid FD leak.
        closeForcibly();
        closeFuture.setClosed();
        safeSetFailure(promise, t);
    }
}

// 调用java底层去注册
protected void doRegister() throws Exception {
    boolean selected = false;
    for (;;) {
        try {
            // 调用java底层去注册
            selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this);
            return;
        } catch (CancelledKeyException e) {
            if (!selected) {
                // Force the Selector to select now as the "canceled" SelectionKey may still be
                // cached and not removed because no Select.select(..) operation was called yet.
                eventLoop().selectNow();
                selected = true;
            } else {
                // We forced a select operation on the selector before but the SelectionKey is still cached
                // for whatever reason. JDK bug ?
                throw e;
            }
        }
    }
}

// HeadContext的channelActive
public void channelActive(ChannelHandlerContext ctx) {
    // 向上传播
    ctx.fireChannelActive();
	// 调用channel的read
    readIfIsAutoRead();
}
// 调用channel的read
private void readIfIsAutoRead() {
    if (channel.config().isAutoRead()) {
        channel.read();
    }
}

// 调用channel.pipeline.read
public Channel read() {
    pipeline.read();
    return this;
}

// channel.pipeline.read从TailContext开始
// 一路向上传最后到HeadContext.read()
public final ChannelPipeline read() {
    tail.read();
    return this;
}

//HeadContext.read()
public void read(ChannelHandlerContext ctx) {
    //NioByteUnsafe.AbstractUnsafe.beginRead
    unsafe.beginRead();
}
//NioByteUnsafe.AbstractUnsafe.beginRead
public final void beginRead() {
    assertEventLoop();

    try {
        doBeginRead();
    } catch (final Exception e) {
        invokeLater(new Runnable() {
            @Override
            public void run() {
                pipeline.fireExceptionCaught(e);
            }
        });
        close(voidPromise());
    }
}

//NioByteUnsafe.AbstractUnsafe.doBeginRead
//注册read就绪事件
protected void doBeginRead() throws Exception {
    // Channel.read() or ChannelHandlerContext.read() was called
    final SelectionKey selectionKey = this.selectionKey;
    if (!selectionKey.isValid()) {
        return;
    }

    readPending = true;

    final int interestOps = selectionKey.interestOps();
    // 将selectionKey的interestOps设置为selectionKey.OP_READ
    if ((interestOps & readInterestOp) == 0) {
        selectionKey.interestOps(interestOps | readInterestOp);
    }
}

```







### 总结

检测新连接：

netty 在服务端chanel绑定的bossGroup线程NioEventLoop里轮询到accept事件



创建NioSocketChannel：

接着调用jdk的accept的到jdk的channel，然后将它封装成netty的NioSocketChannel，NioSocketChannel重要的组件unsafe和pipeline，unsafe负责读写，pipeline负责业务逻辑连



分配线程级注册selector：

然后通过ServerBootstrapAcceptor.channelRead 给当前NioSocketChannel分配NioEventLoop及注册selector



向seletor注册读事件：

通过传播channelActive事件向seletor注册读事件

















